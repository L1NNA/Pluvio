{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cf18c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.9/site-packages (4.56.2)\n",
      "Requirement already satisfied: sentence_transformers in /opt/conda/lib/python3.9/site-packages (5.1.1)\n",
      "Requirement already satisfied: utils in /opt/conda/lib/python3.9/site-packages (1.0.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.9/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/conda/lib/python3.9/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /opt/conda/lib/python3.9/site-packages (from transformers) (0.35.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.9/site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/jovyan/.local/lib/python3.9/site-packages (from transformers) (2023.3.23)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.9/site-packages (from sentence_transformers) (1.8.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /opt/conda/lib/python3.9/site-packages (from sentence_transformers) (4.15.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.9/site-packages (from sentence_transformers) (2.8.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.9/site-packages (from sentence_transformers) (1.0.2)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.9/site-packages (from sentence_transformers) (9.0.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.9.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.7)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.9/site-packages (from torch>=1.11.0->sentence_transformers) (2.5.1)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /opt/conda/lib/python3.9/site-packages (from torch>=1.11.0->sentence_transformers) (1.13.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /opt/conda/lib/python3.9/site-packages (from torch>=1.11.0->sentence_transformers) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /opt/conda/lib/python3.9/site-packages (from torch>=1.11.0->sentence_transformers) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /opt/conda/lib/python3.9/site-packages (from torch>=1.11.0->sentence_transformers) (11.7.3.90)\n",
      "Requirement already satisfied: triton==3.4.0 in /opt/conda/lib/python3.9/site-packages (from torch>=1.11.0->sentence_transformers) (3.4.0)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /opt/conda/lib/python3.9/site-packages (from torch>=1.11.0->sentence_transformers) (2.27.3)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /opt/conda/lib/python3.9/site-packages (from torch>=1.11.0->sentence_transformers) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /opt/conda/lib/python3.9/site-packages (from torch>=1.11.0->sentence_transformers) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /opt/conda/lib/python3.9/site-packages (from torch>=1.11.0->sentence_transformers) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /opt/conda/lib/python3.9/site-packages (from torch>=1.11.0->sentence_transformers) (0.7.1)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /opt/conda/lib/python3.9/site-packages (from torch>=1.11.0->sentence_transformers) (9.10.2.21)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from torch>=1.11.0->sentence_transformers) (3.0.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /opt/conda/lib/python3.9/site-packages (from torch>=1.11.0->sentence_transformers) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /opt/conda/lib/python3.9/site-packages (from torch>=1.11.0->sentence_transformers) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /opt/conda/lib/python3.9/site-packages (from torch>=1.11.0->sentence_transformers) (12.8.90)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /opt/conda/lib/python3.9/site-packages (from torch>=1.11.0->sentence_transformers) (10.3.9.90)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/conda/lib/python3.9/site-packages (from torch>=1.11.0->sentence_transformers) (1.14.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.9/site-packages (from triton==3.4.0->torch>=1.11.0->sentence_transformers) (4.11.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /opt/conda/lib/python3.9/site-packages (from triton==3.4.0->torch>=1.11.0->sentence_transformers) (59.8.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->transformers) (1.26.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests->transformers) (2.0.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn->sentence_transformers) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.9/site-packages (from scikit-learn->sentence_transformers) (1.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.9/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence_transformers) (1.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.0.1)\n",
      "Requirement already satisfied: decorator<5,>=4.3 in /opt/conda/lib/python3.9/site-packages (from networkx->torch>=1.11.0->sentence_transformers) (4.4.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.9/site-packages (from importlib-metadata->triton==3.4.0->torch>=1.11.0->sentence_transformers) (3.7.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers sentence_transformers utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b628888a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: /opt/conda/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy.typing'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_VISIBLE_DEVICES\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer, InputExample, losses, models, evaluation, util\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/sentence_transformers/__init__.py:15\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     11\u001b[0m     export_dynamic_quantized_onnx_model,\n\u001b[1;32m     12\u001b[0m     export_optimized_onnx_model,\n\u001b[1;32m     13\u001b[0m     export_static_quantized_openvino_model,\n\u001b[1;32m     14\u001b[0m )\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcross_encoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     16\u001b[0m     CrossEncoder,\n\u001b[1;32m     17\u001b[0m     CrossEncoderModelCardData,\n\u001b[1;32m     18\u001b[0m     CrossEncoderTrainer,\n\u001b[1;32m     19\u001b[0m     CrossEncoderTrainingArguments,\n\u001b[1;32m     20\u001b[0m )\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ParallelSentencesDataset, SentencesDataset\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mLoggingHandler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LoggingHandler\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/sentence_transformers/cross_encoder/__init__.py:3\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mCrossEncoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CrossEncoder\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_card\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CrossEncoderModelCardData\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CrossEncoderTrainer\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:29\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_onnx_model, load_openvino_model\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcross_encoder\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfit_mixin\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FitMixin\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcross_encoder\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_card\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CrossEncoderModelCardData, generate_model_card\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcross_encoder\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     32\u001b[0m     cross_encoder_init_args_decorator,\n\u001b[1;32m     33\u001b[0m     cross_encoder_predict_rank_args_decorator,\n\u001b[1;32m     34\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/sentence_transformers/cross_encoder/fit_mixin.py:19\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenization_utils_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BatchEncoding\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcross_encoder\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining_args\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CrossEncoderTrainingArguments\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mNoDuplicatesDataLoader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NoDuplicatesDataLoader\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSentenceLabelDataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceLabelDataset\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSentenceEvaluator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceEvaluator\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/sentence_transformers/datasets/__init__.py:13\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mDenoisingAutoEncoderDataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DenoisingAutoEncoderDataset\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mNoDuplicatesDataLoader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NoDuplicatesDataLoader\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mParallelSentencesDataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ParallelSentencesDataset\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSentenceLabelDataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceLabelDataset\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSentencesDataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentencesDataset\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/sentence_transformers/datasets/ParallelSentencesDataset.py:19\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InputExample\n\u001b[1;32m     22\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/sentence_transformers/SentenceTransformer.py:24\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Callable, Literal, overload\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnpt\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmultiprocessing\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmp\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy.typing'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"0\"\n",
    "device = 'cuda:0'\n",
    "from ST4.sentence_transformers import SentenceTransformer, InputExample, losses, models, evaluation, util\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from torch.utils.data import DataLoader\n",
    "import pickle\n",
    "import re\n",
    "import torch\n",
    "import gc\n",
    "from sentence_transformers import SentencesDataset  \n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, auc, precision_score, recall_score, roc_auc_score, roc_curve, f1_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import tensorflow as tf\n",
    "import torch.nn as nn \n",
    "from torch import Tensor\n",
    "from typing import Dict, Iterable\n",
    "from torch.autograd import Variable\n",
    "from Utils import cuda\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import json\n",
    "#import from the original sentence transformer .py file\n",
    "# from SentenceTrans import SentenceTransformer\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2607439",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Collecting data from pickle files.\n",
    "'''\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('datasets/pickle_files/TrainingData.pkl', 'rb') as f:\n",
    "    training = pickle.load(f)\n",
    "with open('datasets/pickle_files/TestingDataLib.pkl', 'rb') as f:\n",
    "    test_libs = pickle.load(f)\n",
    "with open('datasets/pickle_files/TestingDataArch.pkl', 'rb') as f:\n",
    "    test_arch = pickle.load(f)\n",
    "with open('datasets/pickle_files/TestingDataLib_and_Arch.pkl', 'rb') as f:\n",
    "    test_libsarch = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf54be85",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'cached_download' from 'huggingface_hub' (/opt/conda/lib/python3.9/site-packages/huggingface_hub/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mST4\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[1;32m      2\u001b[0m optimizations \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mO0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mO1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mO2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mO3\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      3\u001b[0m architectures \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpowerpc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmips\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marm\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgcc32\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgcc\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/RESEARCHES/Pluvio/IMPORTANT/ST4/sentence_transformers/__init__.py:3\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.2.2\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m __MODEL_HUB_ORGANIZATION__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence-transformers\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentencesDataset, ParallelSentencesDataset\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mLoggingHandler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LoggingHandler\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSentenceTransformer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n",
      "File \u001b[0;32m~/RESEARCHES/Pluvio/IMPORTANT/ST4/sentence_transformers/datasets/__init__.py:3\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mDenoisingAutoEncoderDataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DenoisingAutoEncoderDataset\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mNoDuplicatesDataLoader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NoDuplicatesDataLoader\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mParallelSentencesDataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ParallelSentencesDataset\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSentencesDataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentencesDataset\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSentenceLabelDataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceLabelDataset\n",
      "File \u001b[0;32m~/RESEARCHES/Pluvio/IMPORTANT/ST4/sentence_transformers/datasets/ParallelSentencesDataset.py:4\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgzip\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InputExample\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m List\n",
      "File \u001b[0;32m~/RESEARCHES/Pluvio/IMPORTANT/ST4/sentence_transformers/SentenceTransformer.py:12\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ndarray\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HfApi, HfFolder, Repository, hf_hub_url, cached_download\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn, Tensor, device\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'cached_download' from 'huggingface_hub' (/opt/conda/lib/python3.9/site-packages/huggingface_hub/__init__.py)"
     ]
    }
   ],
   "source": [
    "from ST4.sentence_transformers import SentenceTransformer\n",
    "optimizations = ['O0', 'O1', 'O2', 'O3']\n",
    "architectures = [\"powerpc\", \"mips\", \"arm\", \"gcc32\", \"gcc\"]\n",
    "libs = [\"busybox_unstripped\", 'openssl', 'sqlite3', \"coreutils\", \"curl\", \"magick\", \"puttygen\"]\n",
    "\n",
    "def pairGenerator(data):\n",
    "    pairs = []\n",
    "    for pair in data:\n",
    "        \n",
    "        for i in range(len(optimizations)):\n",
    "            if optimizations[i] in pair[3]:\n",
    "                opt0 = i\n",
    "                break\n",
    "                \n",
    "        for i in range(len(optimizations)):\n",
    "            if optimizations[i] in pair[4]:\n",
    "                opt1 = i    \n",
    "                break\n",
    "                \n",
    "        for j in range(len(architectures)):\n",
    "            if architectures[j] in pair[3]:\n",
    "                arc0 = j\n",
    "                break\n",
    "                \n",
    "        for j in range(len(architectures)):\n",
    "            if architectures[j] in pair[4]:\n",
    "                arc1 = j   \n",
    "                break\n",
    "                \n",
    "        for k in range(len(libs)):\n",
    "            if libs[k] in pair[3]:\n",
    "                lib0 = k\n",
    "                break\n",
    "                \n",
    "        for k in range(len(libs)):\n",
    "            if libs[k] in pair[4]:\n",
    "                lib1 = k    \n",
    "                break\n",
    "        pairs.append(InputExample(texts=[pair[1], pair[0]], label=float(pair[2]), archs=[arc1, arc0], opts=[opt1, opt0], libs=[lib1, lib0]))\n",
    "    return pairs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_examples = pairGenerator(training[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef0295ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_1 = 1e-5\n",
    "beta_2 = 5e-1\n",
    "sent_embed_dim = 768\n",
    "arch_opt_embed_dim = 8\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "class CosineSimilarityLoss(nn.Module):\n",
    "    \n",
    "    def __init__(self, model: SentenceTransformer, loss_fct = nn.MSELoss(), cos_score_transformation=nn.Identity()):\n",
    "        super(CosineSimilarityLoss, self).__init__()\n",
    "        self.model = model\n",
    "        self.loss_fct = loss_fct\n",
    "        self.cos_score_transformation = cos_score_transformation\n",
    "        \n",
    "        self.embedding_arch = nn.Embedding(len(architectures), arch_opt_embed_dim).to(device)\n",
    "        self.embedding_opts = nn.Embedding(len(optimizations), arch_opt_embed_dim).to(device)\n",
    "        \n",
    "        self.encoder = nn.Linear(sent_embed_dim+arch_opt_embed_dim*2, sent_embed_dim)\n",
    "        \n",
    "        # self.decode = nn.Sequential(\n",
    "        #     nn.Linear(sent_embed_dim+arch_opt_embed_dim*2, sent_embed_dim))\n",
    "        self.decode = nn.Sequential(\n",
    "            nn.Linear(sent_embed_dim, sent_embed_dim))\n",
    "        \n",
    "    \n",
    "    def reparametrize_n(self, mu, std, archs, opts, libs, n=1):\n",
    "        # reference :\n",
    "        # http://pytorch.org/docs/0.3.1/_modules/torch/distributions.html#Distribution.sample_n\n",
    "        def expand(v):\n",
    "            if isinstance(v, Number):\n",
    "                return torch.Tensor([v]).expand(n, 1)\n",
    "            else:\n",
    "                return v.expand(n, *v.size())\n",
    "\n",
    "        if n != 1 :\n",
    "            mu = expand(mu)\n",
    "            std = expand(std)\n",
    "\n",
    "        eps = Variable(cuda(std.data.new(std.size()).normal_(), std.is_cuda))\n",
    "\n",
    "        return mu + eps * std\n",
    "    \n",
    "    \n",
    "    def encode_embed(self, embed, archs=None, opts=None, libs=None, num_sample=1):\n",
    "        # embd: [batch, sent_embed_dim]\n",
    "        \n",
    "        # print(archs, opts, libs, embed.shape[0])\n",
    "        # embedding of the first arch/opt\n",
    "        batch_size = embed.shape[0]\n",
    "        embed_arch_0 = self.embedding_arch(torch.zeros(batch_size).type(torch.LongTensor).to(device))\n",
    "        embed_opts_0 = self.embedding_opts(torch.zeros(batch_size).type(torch.LongTensor).to(device))\n",
    "        \n",
    "        if archs is None:\n",
    "            embed_arch = embed_arch_0\n",
    "        else:\n",
    "            embed_arch = self.embedding_arch(archs)\n",
    "        \n",
    "        if opts is None:\n",
    "            embed_opts = embed_opts_0\n",
    "        else:\n",
    "            embed_opts = self.embedding_opts(opts)\n",
    "        \n",
    "        encoded = self.encoder(torch.cat((embed, embed_arch, embed_opts), -1))\n",
    "        \n",
    "        mu = encoded\n",
    "        \n",
    "        '''\n",
    "        HERE\n",
    "        '''\n",
    "        # std = F.softplus(encoded-10, beta=1.8, threshold=20)\n",
    "        std = F.softplus(encoded-10, beta=1.8, threshold=20)\n",
    "        \n",
    "\n",
    "        encoding = self.reparametrize_n(mu, std, archs, opts, libs, num_sample)\n",
    "        # logit = self.decode(torch.cat((encoding, embed_arch_0, embed_opts_0), -1))\n",
    "        logit = self.decode(encoding)\n",
    "\n",
    "        if num_sample == 1 : pass\n",
    "        elif num_sample > 1 : logit = F.softmax(logit, dim=2).mean(0)\n",
    "\n",
    "        \n",
    "        return (mu, std), logit\n",
    "    \n",
    "#     def save(self, path):\n",
    "#         torch.save(self.state_dict(), path)\n",
    "#         with open(os.path.join(path, 'modules.json'), 'w') as fOut:\n",
    "#             json.dump(modules_config, fOut, indent=2)\n",
    "    \n",
    "#     @classmethod\n",
    "#     def load(cls, path):\n",
    "#         model = MyModelDefinition(args)\n",
    "#         model.load_state_dict(torch.load('load/from/path/model.pth'))\n",
    "    def __repr__(self):\n",
    "        return \"CosinSimilarityLoss\"\n",
    "\n",
    "    def forward(self, sentence_features: Iterable[Dict[str, Tensor]], labels: Tensor, archs, opts, libs):\n",
    "        embeddings = [self.model(sentence_feature)['sentence_embedding'] for sentence_feature in sentence_features]\n",
    "        e0 = embeddings[0]\n",
    "        e1 = embeddings[1]\n",
    "        # print(e0.shape, e1.shape)\n",
    "        \n",
    "        arch0 = torch.Tensor([v[0] for v in archs]).type(torch.LongTensor).to(device)\n",
    "        arch1 = torch.Tensor([v[1] for v in archs]).type(torch.LongTensor).to(device)\n",
    "        opts0 = torch.Tensor([v[0] for v in opts]).type(torch.LongTensor).to(device)\n",
    "        opts1 = torch.Tensor([v[1] for v in opts]).type(torch.LongTensor).to(device)\n",
    "        lib0 = torch.Tensor([v[0] for v in libs]).type(torch.LongTensor).to(device)\n",
    "        lib1 = torch.Tensor([v[1] for v in libs]).type(torch.LongTensor).to(device)\n",
    "        \n",
    "        (mu0, std0), logit0 = self.encode_embed(e0, arch0, opts0, lib0)\n",
    "        (mu1, std1), logit1 = self.encode_embed(e1, arch1, opts1, lib1)\n",
    "        \n",
    "        \n",
    "        output = self.cos_score_transformation(torch.cosine_similarity(\n",
    "            logit0,\n",
    "            logit1,\n",
    "        ))\n",
    "        \n",
    "        information_loss = -0.5*(1+2*std0.log()-mu0.pow(2)-std0.pow(2)).sum(1).mean().div(math.log(2))\n",
    "        information_loss += -0.5*(1+2*std1.log()-mu1.pow(2)-std1.pow(2)).sum(1).mean().div(math.log(2))\n",
    "        \n",
    "        cosine_loss = self.loss_fct(output, labels.view(-1))\n",
    "        \n",
    "        # cosine_loss += information_loss/2 * 1e-3\n",
    "        cosine_loss += information_loss/2 * beta_1\n",
    "        \n",
    "        if 'probs' in sentence_features[0]:\n",
    "            # rl_expected_reward = features['probs'] * 1 *  (-1 * cosine_loss)\n",
    "            sentence_features = list(sentence_features)\n",
    "            combined_probs = sentence_features[0]['probs'] * sentence_features[1]['probs']  # [batch, 1]\n",
    "\n",
    "            reward = 1/cosine_loss\n",
    "\n",
    "            rl_loss = combined_probs * reward * -1\n",
    "            # REINFORCE Algorithm\n",
    "\n",
    "            # print(output.shape,labels.shape, cosine_loss.shape, rl_loss.shape, )\n",
    "\n",
    "            cosine_loss += rl_loss.sum() * beta_2\n",
    "        \n",
    "        return cosine_loss\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "class Removal(nn.Module):\n",
    "    \n",
    "    def __init__(self, word_embedding_model, max_len=1024):   \n",
    "        super(Removal, self).__init__()\n",
    "        \n",
    "        # word_embedding_model.max_seq_length = 1024\n",
    "        self.word_embedding_model_input_len_limit = word_embedding_model.max_seq_length\n",
    "        self.word_embedding_model = word_embedding_model\n",
    "        self.word_embedding_model.max_seq_length = max_len\n",
    "        embedding_layer = list(word_embedding_model.modules())[3]\n",
    "        \n",
    "        \n",
    "   \n",
    "        self.embedding = embedding_layer#.to(device)\n",
    "        # self.conv1d = nn.Conv1d(1024, 128, 1).to(device)\n",
    "        # 768 in-channels, 1 out channels, window size of 10, padded to same as input length\n",
    "        '''\n",
    "        TUNE layer nodes (node = 3)\n",
    "        '''\n",
    "        self.conv1d = nn.Conv1d(768, 1, 3, padding='same')# in channel 768\n",
    "        # self.conv1d = nn.Conv1d(8, 1, 2, padding='same')# in channel 768\n",
    "        # self.linear = nn.Linear(in_features=64, out_features=1).to(device)\n",
    "        self.activation = nn.Softmax(dim=1)#.to(device)\n",
    "        # self.activation = nn.Softplus()#.to(device)\n",
    "    \n",
    "   \n",
    "    def __repr__(self):\n",
    "        return \"Removal\"\n",
    "    \n",
    "#     def save_model(self, path):\n",
    "#         torch.save(self.state_dict(), path)\n",
    "        \n",
    "#     def load_model(self, path):\n",
    "#         model = torch.load(path)\n",
    "    \n",
    "#     def save(self, path):\n",
    "#         if os.path.isdir(path):\n",
    "#             path = os.path.join(path, 'removal.pth')\n",
    "#         torch.save(self.state_dict(), path)\n",
    "#         # torch.save(self, path)\n",
    "#         # config_path = os.path.join(os.path.dirname(path), 'removal.json')\n",
    "#         # with open(config_path, 'w') as fOut:\n",
    "#         #     json.dump(modules_config, fOut, indent=2)\n",
    "        \n",
    "    \n",
    "    \n",
    "#     # @classmethod\n",
    "#     # def load(cls, path):\n",
    "#         # model = MyModelDefinition(args)\n",
    "#         # model.load_state_dict(torch.load('load/from/path/removal.pth'))\n",
    "#     def load(path):\n",
    "#         if os.path.isdir(path):\n",
    "#             path = os.path.join(path, 'removal.pth')\n",
    "#         model = torch.load(path)\n",
    "\n",
    "\n",
    "    def forward(self, features: Dict[str, Tensor]):\n",
    "        if not 'sentence_embedding' in features:\n",
    "            # for k,v in features.items():\n",
    "            #     print(k, v.shape, v.device)\n",
    "            # print(\"========================\")\n",
    "            \n",
    "            attention_mask = features['attention_mask'].to(device)#.to(device) #torch.Size([10, 1024])\n",
    "            input_ids = features['input_ids'].to(device) #torch.Size([10, 1024])\n",
    "            \n",
    "            embd = self.embedding(input_ids).permute(0, 2, 1) # input_ids,shape = [10, 1024]\n",
    "            # print(embed.shape) #[10, 768, 1024]\n",
    "            # print(\"0\", embd.shape)\n",
    "            \n",
    "            probs = self.conv1d(embd) # [10, 1, 1024]\n",
    "            # print(\"1\", probs.shape)\n",
    "            probs = self.activation(probs)\n",
    "            # print(\"2\", probs.shape)\n",
    "            # probs = torch.flatten(probs, start_dim=1)\n",
    "            probs = probs.permute(0, 2, 1).squeeze(-1) #[10, 1024]\n",
    "            # print(\"3\", probs.shape)\n",
    "            # probs = self.activation(probs).squeeze(-1) # \n",
    "            # print(\"4\", probs.shape)\n",
    "            # print(probs.shape) #[10, 1024]\n",
    "            \n",
    "            seq_len = probs.shape[1]\n",
    "            if seq_len > self.word_embedding_model_input_len_limit:\n",
    "                seq_len = self.word_embedding_model_input_len_limit\n",
    "            \n",
    "            top_k_probs, top_k_ind = probs.topk(seq_len, largest=True)\n",
    "            # print(top_k_probs)\n",
    "            # print(top_k_ind)\n",
    "            \n",
    "            input_ids = torch.gather(input_ids, 1, top_k_ind)\n",
    "            attention_mask = torch.gather(attention_mask, 1, top_k_ind)\n",
    "            \n",
    "            features['attention_mask'] = attention_mask\n",
    "            features['input_ids'] = input_ids\n",
    "            \n",
    "            \n",
    "            '''\n",
    "            TUNE\n",
    "            '''\n",
    "            #top_k_probs\n",
    "            features['probs'] = torch.sum(top_k_probs, dim=1).unsqueeze(1) # [10, 1]\n",
    "            # probs * 1 * (predicted - truth)\n",
    "        return features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818ad6bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ad65a5668324a8485140daa259825d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "418a60e2837d401896b5f383d7f73f77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/torch/nn/modules/conv.py:309: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "BUILD MODEL\n",
    "'''    \n",
    "\n",
    "st = SentenceTransformer('all-mpnet-base-v2')\n",
    "word_embedding_model = list(st.modules())[1]\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "Pluvio = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "\n",
    "Removal_Module = Removal(word_embedding_model)\n",
    "Pluvio.removal_module = Removal_Module\n",
    "\n",
    "train_dataset = SentencesDataset(train_examples, Pluvio)\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=False, batch_size=batch_size)\n",
    "train_loss = CosineSimilarityLoss(model=Pluvio)\n",
    "\n",
    "Pluvio.FIT(train_objectives=[(train_dataloader, train_loss)], epochs=3, warmup_steps=50, show_progress_bar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0dac17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Evaluation(X_test):\n",
    "    with torch.inference_mode():\n",
    "        truth = [] # 0 or 1\n",
    "        predictions = [] # 0-1\n",
    "\n",
    "        pairs0 = [p[0] for p in X_test]\n",
    "        pairs1 = [p[1] for p in X_test]\n",
    "        truth = [p[2] for p in X_test]\n",
    "        sen_embed0 = Pluvio.encode(pairs0)\n",
    "        sen_embed1 = Pluvio.encode(pairs1)\n",
    "        _, sen_logits0 = train_loss.encode_embed(torch.Tensor(sen_embed0).to(device))\n",
    "        _, sen_logits1 = train_loss.encode_embed(torch.Tensor(sen_embed1).to(device))\n",
    "\n",
    "        predictions = util.pairwise_cos_sim(sen_logits0, sen_logits1).detach().cpu()\n",
    "        # print(predictions, truth)\n",
    "\n",
    "        fpr, tpr, thresholds = roc_curve(truth, predictions)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "\n",
    "        # find optimal threshold\n",
    "        optimal_idx = np.argmax(tpr - fpr)\n",
    "        optimal_threshold = thresholds[optimal_idx]\n",
    "        pred_labels = predictions >= optimal_threshold\n",
    "\n",
    "        res = {\n",
    "            'auc': roc_auc,\n",
    "            'acc': accuracy_score(truth, pred_labels),  # Maybe change to macro?\n",
    "            'prc': precision_score(truth, pred_labels),\n",
    "            'rcl': recall_score(truth, pred_labels),\n",
    "            'pav': np.mean([p for t, p in zip(truth, predictions) if t == 1]),\n",
    "            'pvr': np.var([p for t, p in zip(truth, predictions) if t == 1]),\n",
    "            'nav': np.mean([p for t, p in zip(truth, predictions) if t == 0]),\n",
    "            'nvr': np.var([p for t, p in zip(truth, predictions) if t == 0]),\n",
    "            'f1': f1_score(truth, pred_labels),\n",
    "            'opt': optimal_threshold,\n",
    "        }\n",
    "        # print(\"Testing based on the out of sample data\")\n",
    "        print(res)\n",
    "\n",
    "    \n",
    "#test based on the different and same libs. \n",
    "# to see if it is underfit \n",
    "Evaluation(training[:160])\n",
    "Evaluation(test_arch[:160])\n",
    "Evaluation(test_libs[:160])\n",
    "Evaluation(test_libsarch[:160])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
